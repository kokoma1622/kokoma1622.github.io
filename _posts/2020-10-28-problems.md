---
title: "[ML] Problems in Learning"
date: 2020-10-28 22:58:19 -0400
categories: MachineLearning,TroubleShooting
---

데이터셋을 완성한 후 러닝하면서 발생한 문제점들 정리하는 페이지.

1. 정확도가 75%로 고정되는 문제.
model structure, optimizer, learning rate, decay, regularizer 등을 바꿔도 정확도는 항상 75%로 같았다.
model이 승패를 예측하는 binary classification이다보니, model이 input에 상관 없이 항상 같은 결과를 예측하는 현상이 발생했다고 생각하였다.
혹시 input data가 잘못됐나 생각하여 label을 확인해보니 0과 1은 놀랍게도(?) 엄대엄.
큰수의 법칙이 맞다는 것도 알고 당연한 것도 알지만, 실제로 보니 놀랍긴 하네.

그래서 model을 학습시킨 후, test 대신 predict를 하고 np.sum을 해보니 test dataset 길이랑 같잖아?
해서 전부 1로 분류하는 상태라 생각하였다.
자고 일어나서 생각해보니 predict는 input의 결과를 softmax하여 출력하니 한 input의 output의 sum은 1인 것이 당연...
그래서 np.sum(np.argamx)를 통해 0과 1 중 어디로 분류하는지 확인하였다.
결과가 size 2인 list이다보니, index는 0 또는 1이기 때문에 단순 sum으로도 1로 분류된 개수를 확인할 수 있었다.
대락 절반 정도가 1로 분류.
문제는 다시 제자리로.
아마 75%가 단순한 linear CNN으로는 학습 데이터셋의 한계가 아닐까 추측.

2. 그래도 learning rate와 model 변경 과정 들
learning rate를 0.001부터 0.0000001까지 적용해보았고,
CNN model 역시 convolutional layer을 1층부터 4층까지 쌓아보았다.
그러나 정확도느 75%대로 소숫점만 다소 달랐다.
optimizer는 Adamm과 RMSprop을 사용하였고, RMSprop의 경우 rho와 momentum까지 변경하면서 정확도를 확인해보았지만, 75%로 동일.

3. image 문제
막대그래프 두께를 1, 간격을 1로 하면 막대 5개를 두는데 필요한 공간은 9 pixel.
적절한 막대의 높이로 12를 선택하고 여기서 아래위로 1씩 여백, 양 옆에 적절한 여백을 줘 image 크기를 14x14로 설계했었다.
그러나 14x14는 CNN을 사용할 때 입력의 크기로 너무 작은 것이 아닌가 생각하여 28x28로 늘렸는데,
코드를 고치는 과정에서 cs는 별도 코드를 사용하기에 막대 높이를 12에서 24로 늘렸으나,
cs를 제외한 레벨, 킬, 데스, 어시스트는 막대 높이를 24로 늘리는 수정을 하지 못하여 막대가 납작하게 저장되었다.
테스트 데이터셋도 같은 방식으로 저장되어 문제는 없었지만, 제대로 수정을 한다면 결과가 더 좋을수도 있을 것으로 추측된다.

4. champion random dictionary
image를 만들 때 champion 정보를 image에 담기 위해 categorical data인 champion을 10~161의 숫자로 수치화하여 막대그래프의 배경으로 넣었다.
이 때 champion to integer 매칭을 랜덤하게 진행했는데, 데이터셋을 만드는 과정에서 이 매칭 정보를 별도로 저장하지 않았다.
그래서 model 학습과 테스트가 끝난 이후 내 랭크 게임을 바탕으로 데이터를 새로 생성하여 모델에 통과시키려 할 때, 
데이터셋을 만들 때의 매칭 정보가 없어 champion을 integer로 변환할 수 없었다.


우선 28x28이던 image 크기를 14x14로 줄이면서 매칭 정보를 저장해놓은 데이터셋을 새로 만들었다.
내일이나 모레 to be continued
